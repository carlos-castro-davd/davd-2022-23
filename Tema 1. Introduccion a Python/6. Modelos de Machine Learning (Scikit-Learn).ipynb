{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los entornos más sencillos de aprender para realizar modelos de machine learning, es la librería Scikit-Learn (sklearn). Esta librería dota a los usuarios de una gran variedad de técnicas y métricas con una fácil implementación y unos resultados aceptables.\n",
    "\n",
    "Enlace a la documentación oficial: https://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (classification_report, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error,\n",
    "                            silhouette_score)\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los problemas que contienen un conjunto de variables explicativas y una (o más) variable(s) objetivo se denominan problemas de aprendizaje supervisado. Si además la variable objetivo es contínua, diremos que el problema es de regresión. Por el contrario, si la variable objetivo es categórica, diremos que es un problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga del fichero de datos de clasificación\n",
    "dataset = sklearn.datasets.load_wine()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos a formato dataframe\n",
    "df = pd.DataFrame(data = dataset['data'], columns = dataset['feature_names'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos la variable objetivo\n",
    "df[\"target\"] = dataset[\"target\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alcohol                         0\n",
       "malic_acid                      0\n",
       "ash                             0\n",
       "alcalinity_of_ash               0\n",
       "magnesium                       0\n",
       "total_phenols                   0\n",
       "flavanoids                      0\n",
       "nonflavanoid_phenols            0\n",
       "proanthocyanins                 0\n",
       "color_intensity                 0\n",
       "hue                             0\n",
       "od280/od315_of_diluted_wines    0\n",
       "proline                         0\n",
       "target                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos si hay NAs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.398876\n",
       "0    0.331461\n",
       "2    0.269663\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clases balanceadas?\n",
    "df[\"target\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir train-test\n",
    "X = dataset[\"data\"]\n",
    "y = dataset[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del modelo\n",
    "svm = LinearSVC(C = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlace del modelo : https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       1.00      0.86      0.92        14\n",
      "     class_1       0.86      1.00      0.92        18\n",
      "     class_2       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.94        54\n",
      "   macro avg       0.95      0.94      0.94        54\n",
      "weighted avg       0.95      0.94      0.94        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Metricas para evaluar un clasificador\n",
    "\n",
    "print(classification_report(y_test, predictions, target_names=dataset[\"target_names\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'C:\\\\Anaconda\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sklearn.datasets.load_boston()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos a formato dataframe\n",
    "df = pd.DataFrame(data = dataset['data'], columns = dataset['feature_names'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos la variable objetivo\n",
    "df[\"target\"] = dataset[\"target\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos si hay NAs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que haríamos para sacar información del target? ¿Y de las variables explicativas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir train-test\n",
    "X = dataset[\"data\"].copy()\n",
    "y = dataset[\"target\"].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = ElasticNet()\n",
    "reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html#sklearn.linear_model.ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.56240783, 27.75227414, 35.99831244, 19.32923066, 29.46975195,\n",
       "       30.63265444, 27.54594243,  8.18087926, 14.6143395 , 29.98049923,\n",
       "       29.62687337, 22.46725025, 14.72463847, 31.52788667, 16.88778067,\n",
       "       23.7223952 , 20.79145044, 36.11507811, 19.64645419, 16.2624932 ,\n",
       "       15.56437205, 24.62137127, 31.98613932, 35.64246917, 29.72930641,\n",
       "       21.48608389, 18.08472848, 23.57824703, 25.10371212, 21.61725281,\n",
       "       25.00191853, 33.20642949, 17.04016189, 23.36430104, 23.19251177,\n",
       "       33.01476797, 28.91562459, 17.48120425, 16.04589379, 34.6772319 ,\n",
       "       29.74489641, 20.58687801, 21.62233184, 36.22714622,  8.31766497,\n",
       "       27.31694392, 22.53445409, 27.05991189, 17.52778822, 22.44170364,\n",
       "       32.63729465, 24.673612  , 22.78081362, 12.47576335, 25.76250549,\n",
       "       17.98020475, 13.28083597,  5.21051416, 31.24885571, 14.91423333,\n",
       "       20.53399088, 24.33143843, 23.16530648, 18.61360921, 24.28198026,\n",
       "       28.02827926, 26.45815004, 21.19515471, 25.03927296, 29.99327725,\n",
       "       20.14037312, 28.35657965, 18.17019353, 24.72986633, 18.84639961,\n",
       "       17.96345626, 14.32404182, 18.75837934, 29.99707535,  0.26777952,\n",
       "       30.97041699, 13.34749898, 25.83253461, 19.81446658, 13.97225913,\n",
       "       25.61233458, 18.77148538, 26.08925916, 20.38228153, 31.24741656,\n",
       "       16.45756575, 31.65071333, 23.33529563, 26.49451269, 29.69011484,\n",
       "       27.9245662 , 17.46933516, 30.97924025, 30.67231613, 34.57189147,\n",
       "       19.23376032, 14.68272127, 38.22537312, 16.77553788, 23.51580621,\n",
       "       27.99014386, 16.06374793, 16.75961888, 17.4817928 , 23.77172729,\n",
       "       24.87593796, 20.68605094, 13.65744419, 21.41238826, 16.11696493,\n",
       "       28.09551007, 31.38888598, 11.01470409, 25.22332114, 18.66145125,\n",
       "       22.78364033, 35.83441102, 21.69478512,  9.8478917 , 13.97695258,\n",
       "       22.99600698, 24.5335318 , 23.82691479, 15.01398364, 23.77323613,\n",
       "       24.13668546, 14.89650844, 17.58695082,  6.5782233 , 21.49811442,\n",
       "       18.28446445, 20.34057273, 16.25306935, 19.62232681, 18.90514052,\n",
       "       26.05215069, 23.96973747, 11.37423579, 22.43808079, 30.85474145,\n",
       "       16.15593872, 23.51269569, 21.30868581, 27.52052049, 24.90624725,\n",
       "       16.96007721, 20.08286893])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El RMSE de train del modelo es: 5.011148656865698\n",
      "El MAE de train del modelo es: 3.488622405080966\n",
      "El MAPE de train del modelo es: 16.497360300595002 %\n",
      "\n",
      "El RMSE de test del modelo es: 5.3702524667496085\n",
      "El MAE de test del modelo es: 3.911643047505154\n",
      "El MAPE de test del modelo es: 19.945049945067947 %\n"
     ]
    }
   ],
   "source": [
    "# Metricas de evaluación\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train,predictions_train))\n",
    "mae_train = mean_absolute_error(y_train, predictions_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, predictions_train)\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test,predictions))\n",
    "mae_test = mean_absolute_error(y_test, predictions)\n",
    "mape_test = mean_absolute_percentage_error(y_test, predictions)\n",
    "\n",
    "print(\"El RMSE de train del modelo es: {}\".format(rmse_train))\n",
    "print(f\"El MAE de train del modelo es: {mae_train}\")\n",
    "print(f\"El MAPE de train del modelo es: {100 * mape_train} %\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"El RMSE de test del modelo es: {}\".format(rmse_test))\n",
    "print(f\"El MAE de test del modelo es: {mae_test}\")\n",
    "print(f\"El MAPE de test del modelo es: {100*mape_test} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El aprendizaje no supervisado busca encontrar similitud en los datos sin que exista ninguna etiqueta que los relacione. Estas busquedas suelen estar basadas en distancias y pueden relacionarse de muchas maneras diferentes. Su utilidad se encuentra en casos como detección de anomalías, sistemas recomendadores o búsquedas de temas en textos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas de clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de los datos\n",
    "df = pd.read_csv(\"../../Datos/iris.csv\")\n",
    "df.columns = [x.replace(\".\",\"_\") for x in df.columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[[x for x in df.columns if x != \"variety\"]].values, df[\"variety\"]\n",
    "change_label = {\n",
    "    \"Setosa\": 0,\n",
    "    \"Versicolor\": 1,\n",
    "    \"Virginica\": 2,\n",
    "}\n",
    "y = y.map(change_label).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESTO NO SIEMPRE ES NECESARIO\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=123)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = KMeans(n_clusters = 3, random_state = 123)\n",
    "cluster.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 0, 1, 0, 0, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2,\n",
       "       1, 1, 0, 2, 2, 2, 0, 1, 2, 2, 0, 1, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0,\n",
       "       2, 1, 0, 1, 0, 0, 1, 0, 0, 2, 1, 2, 2, 2, 0, 0, 2, 1, 0, 0, 2, 2,\n",
       "       2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 1, 1, 1, 0, 2, 0, 2, 2, 0, 2, 1, 2,\n",
       "       1, 1, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_train = cluster.predict(X_train)\n",
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 2, 0, 2, 2, 0, 0, 2, 1, 0, 2, 1, 1, 1, 0, 0, 2, 0, 0, 2,\n",
       "       0, 2, 0, 0, 0, 2, 1, 0, 1, 2, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0, 1, 1,\n",
       "       2])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = cluster.predict(X_test)\n",
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, random_state = 123)\n",
    "    kmeanModel.fit(X_train)\n",
    "    distortions.append(kmeanModel.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHwCAYAAAB0TTiEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA/1ElEQVR4nO3debxcdX3/8dcnuQlZCGsCBMIOIksFNCyKLAEiEQjJjL8iLi3qz6JWXFutWJeKrbXUUqu4/FSsuFRAyUrYMQlbWRI2gbCEECAQk7AFQhKyfX9/nHPNTXJzl+TOPXNmXs/H4zzOzJkzM++5E+W+7/d7zomUEpIkSZIklUmfogNIkiRJktRdlllJkiRJUulYZiVJkiRJpWOZlSRJkiSVjmVWkiRJklQ6lllJkiRJUulYZiWpwUXEP0XEr3vhffaJiBQRLfn9GRHx0Vq/b2/oyc8SEb+IiH/egueliDigJzJs5vWPj4jHavX67bxfTT/PloqIL0fEz2r02vMj4tTNPLZF/y4kqZlZZiWp5CJiWZtlXUSsaHP/Az38Xr+IiFUbvecDPfkeW6pNmb53o+1D88zzu/g6vVL+601K6daU0kG1eO16/cNGRJwUEQvabkspfSulVHdZJUmbssxKUsmllLZtXYBngLFttv2mBm95Udv3TCkdXoP32BqDI+KwNvffDzxVVBhJklQblllJag79I+KXEfFaRDwcESNbH4iI3SPiqohYEhFPRcSne/B994+IuyNiaURMjoid2rzvWXmWV/KRu4Pz7R+OiKlt9psbEVe2uf9sRBzRwXv+Cji3zf2/Bn7ZdofNfeaIGAN8GXhvO6POe0fE7fnP8IaIGNrZZ8kfOzIi7s2fdwUwYHPBI+KAiJiZ/7xeyPdv69SIeCIiXo6IH0RE5M/rExFfiYinI2Jx/l1vnz92WUT8XX57j3z0+m/bvN9LkdlglDKfEvv3EfFgnueKiBjQ5vEvRsTCiHg+Ij66uWnDEfEvwPHAJfnP9JLOPk/+vI9ExJz8sesjYu8Ofm4d/fznR8QFEfFI/lr/HREDImIwcC2we6yfZbB7tBmZj/Wj/R/O/929HBEfj4ij8p/LK20/T0TsHxF/iIgX8+/vNxGxw+Zyd/B5hkTE9Ij4XtufiSRpQ5ZZSWoOZwGXAzsAU4BLICtBwFTgAWAP4BTgsxFxWg+9718DHwF2B9YA38vf903Ab4HPAsOAa4CpEdEfmAkcnxe04UA/4Lj8efsB2wIPdvCevwbOiYi+eakZAtzV+mBHnzmldB3wLeCKdkad3w98GNgF6A/8fWefJf88k8gK9k7A74D3dJD9m8ANwI7ACOD7Gz1+JnAUcDhwNtD6PX0oX0YBrT+j1pI1Ezgpv30iMC9fA5wA3JpSSpvJczYwBtgXeEv+Hq2l//PAqcABbV5vEymlfwRuBc7Pf6bnd/Z5ImI82R8VqmQ/01vJfsab6OTfUqsP5K+9P/Am4CsppdeBdwPPt5ll8PxmPsYxwIHAe4HvAv+Yf/ZDgbMjovXzB/CvZP/eDwb2BP5pcz+bzXyenYGbgdtTSp/u4LuRpKZnmZWk5nBbSumalNJasmLVWtKOAoallC5MKa1KKc0Dfgqc08Fr/X0+ItW6XNbBvr9KKT2UF4evkv3i35esFExLKd2YUloNfAcYCLwjz/AacARZSboeeC4i3pzfvzWltK6D91wAPEZWNs5lo1HZLfzMAP+dUno8pbQCuDLPR0efBTiWrIx/N6W0OqX0e+CeDt5jNbA3sHtKaWVK6baNHv92SumVlNIzwPQ2GT4AXJxSmpdSWgZcQFboW2jzxwGy8noR+R8HyH6eMzvI872U0vMppZfI/gDQ+n5n5z+Ph1NKy4FvdPAaHdnc5/kY8K8ppTkppTVkf2A4YjOjsx39/FtdklJ6Nv8c/wK8r5s5v5l/HzcArwO/TSktTik9R1a0jwRIKc3Nc7yRUloCXEwHRb8du5N9H79LKX2lmxklqelYZiWpOfypze3lwIC86OxNNs3yz+WUbERs1w5e6zsppR3aLOd2sO+zbW4/TVbshpL90v506wN5OX2WbKQU1o8mnpDfnkFWCjorX61+STaK+D6ykdq2tuQzw6Y/w23z2x19lt2B5zYaXXuazfsi2eje3fm02Y9sSYb8dguwa0rpSWAZWVE8HrgaeD4iDqLzn2dH79f2u217uzs29/p7A//V5vt5ieznsgeb6uzf0sb5ns6f0x2L2txe0c79bQEiYpeIuDwinouIV8n+7Q2l684gK+I/7mY+SWpKlllJam7PAk9tVE6HpJRO76HX37PN7b3IRh5fAJ4nKywA5McF7gk8l29qLbPH57dn0r0yexVZMZiXUtq4PHb2mbs7rbOjz7IQ2GOj4x732twLpZT+lFL6m5TS7mSjkz9s7zjUzjLk77GG9aVrJvB/gP75aOJMsingOwL3d+H1N7aQbBp0qz03t2Ouuz/TZ4GPbfQdDUwp3dHOvp39W9o43175c7YkV2f+NX/Nt6SUtgM+SFbCu+qnwHXANfkxvZKkDlhmJam53Q28GhH/EBED8+NMD4uIo3ro9T8YEYdExCDgQuD3+VTnK4EzIuKUiOgH/B3wBtBaVmaSHf85MKW0gGwq5xhgZ+C+zt40n9Z8MtDeJVY6+8yLgH3yabld0dFn+V+yUvnpiGiJiCpw9OZeKCL+MiJaS+LLZMVobRcy/Bb4XETsGxHbsv643zX54zOB84Fb8vszgE+RTT/vyutv7ErgwxFxcP7dfq2T/ReRHcvbVT8GLoiIQwEiYvuI+MsOsnT0bwngkxExIrITkH0ZaD2x1iJg58hPltUDhpCNgr8SEXsAX9iC1zifbJr81RExsIdySVJDssxKUhPLi8xYsimoT5GNmv4M6OiX+y/GhteZfaGDfX8F/IJsOukA4NP5+z5GNmr1/fw9x5JdUmhV/vjjZKXg1vz+q2QnLrq9q+UrpTQrn2Lb3c/8u3z9Ymx0zdrNvM9mP0v+eapkU55fJju+c0IHL3cUcFdELCM7UddnUkpduazQz8l+1rfkn2klWVltNZOsaLWW2duAQW3ud0tK6Vqyk3lNB+aSlXbISmR7/gv4P/nZgL/XhdefCPwbcHk+XfchspM1tbdvh/+Wcv9DdmKtefnyz/lzHyX7Q8C8fEpzd6cfb+wbwFuBpcA0Ov6u25VPST+PbHR6crQ5g7QkaUPhSfIkSdLWyM8a/RCwTZvR4LoQEfOBj6aUbio6iySpZzkyK0mSui0iKvnlh3YkG0WdWm9FVpLU2CyzkiRpS3wMWAI8SXZc7yeKjSNJajZOM5YkSZIklY4js5IkSZKk0rHMSpIkSZJKp6XoAFtj6NChaZ999ik6hiRJkiSpBmbPnv1CSmlYe4+Vuszus88+zJo1q+gYkiRJkqQaiIinN/eY04wlSZIkSaVjmZUkSZIklY5lVpIkSZJUOpZZSZIkSVLpWGYlSZIkSaVjmZUkSZIklY5lVpIkSZJUOpZZSZIkSVLpWGYlSZIkSaVjmZUkSZIklY5lVpIkSZJUOpZZSZIkSVLpWGYlSZIkSaVjmZUkSZIklY5lVpIkSZJUOpbZGrjoIpg+fcNt06dn2yVJkiRJW88yWwNHHQVnnw3XXw+LFmVF9uyzs+2SJEmSpK3XUnSARjRqFFxxBYweDYceCgsXwpVXZtslSZIkSVvPkdkaOflkOOww+OMf4bzzLLKSJEmS1JMsszUyfTrMn5/d/sEPNj2GVpIkSZK05SyzNdB6jOwVV8CgQXDiidl9C60kSZIk9QzLbA3cc092jOyYMfDud2f3L788W0uSJEmStp4ngKqBL35x/e1qFa66KhuhbbtdkiRJkrTlHJmtsTPOgH79YMKEopNIkiRJUuOwzNbY9ttnZzaeOBFSKjqNJEmSJDUGy2wvqFbhySfhoYeKTiJJkiRJjcEy2wvGjYMIpxpLkiRJUk+xzPaCXXeF447LphpLkiRJkraeZbaXVCrwwAMwb17RSSRJkiSp/CyzvaRSydaOzkqSJEnS1rPM9pJ994UjjrDMSpIkSVJPsMz2okoF7rgD/vSnopNIkiRJUrlZZntRtZpda3by5KKTSJIkSVK5WWZ70aGHwgEHeIkeSZIkSdpaltleFJGNzv7hD/DKK0WnkSRJkqTyssz2skoF1qyBadOKTiJJkiRJ5WWZ7WVHHw3DhzvVWJIkSZK2hmW2l/Xpk43OXncdLF9edBpJkiRJKifLbAEqlazI3nBD0UkkSZIkqZwsswU48UTYcUeYOLHoJJIkSZJUTpbZAvTrB2PHwtSpsHp10WkkSZIkqXwsswWpVODll2HmzKKTSJIkSVL5WGYL8q53waBBTjWWJEmSpC1hmS3IoEEwZkxWZtetKzqNJEmSJJWLZbZA1SosXAh33110EkmSJEkqF8tsgc44A1panGosSZIkSd1lmS3QDjvAySfDhAmQUtFpJEmSJKk8LLMFq1Zh7lx4+OGik0iSJElSeVhmCzZuHERko7OSJEmSpK6xzBZst93gHe/wuFlJkiRJ6g7LbB2oVOD+++Gpp4pOIkmSJEnlYJmtA5VKtnZ0VpIkSZK6xjJbB/bbDw4/3DIrSZIkSV1lma0TlQrcfjssWlR0EkmSJEmqf5bZOlGtZteanTy56CSSJEmSVP8ss3XisMNg//2daixJkiRJXVHzMhsRfSPivoi4Or+/U0TcGBFP5Osd2+x7QUTMjYjHIuK0WmerJxHZVOObb4alS4tOI0mSJEn1rTdGZj8DzGlz/0vAzSmlA4Gb8/tExCHAOcChwBjghxHRtxfy1Y1qFVavhmnTik4iSZIkSfWtpmU2IkYAZwA/a7N5HHBZfvsyYHyb7ZenlN5IKT0FzAWOrmW+enPMMTB8OEyYUHQSSZIkSapvtR6Z/S7wRWBdm227ppQWAuTrXfLtewDPttlvQb6tafTpA+PHw7XXwooVRaeRJEmSpPpVszIbEWcCi1NKs7v6lHa2pXZe97yImBURs5YsWbJVGetRpQLLl8ONNxadRJIkSZLqVy1HZo8DzoqI+cDlwMkR8WtgUUQMB8jXi/P9FwB7tnn+COD5jV80pfSTlNLIlNLIYcOG1TB+MU46CXbYwanGkiRJktSRmpXZlNIFKaURKaV9yE7s9IeU0geBKcC5+W7nAq1XVp0CnBMR20TEvsCBwN21ylev+vWDsWNh6tTsZFCSJEmSpE0VcZ3ZbwOjI+IJYHR+n5TSw8CVwCPAdcAnU0prC8hXuEoFXnoJbrml6CSSJEmSVJ8ipU0OSy2NkSNHplmzZhUdo8ctXw5Dh8JHPgKXXFJ0GkmSJEkqRkTMTimNbO+xIkZm1YlBg2DMGJg0Cdat63R3SZIkSWo6ltk6VanAc8/BPfcUnUSSJEmS6o9ltk6deSa0tMDEiUUnkSRJkqT6Y5mtUzvuCKNGZZfoKfFhzZIkSZJUE5bZOlatwhNPwCOPFJ1EkiRJkuqLZbaOjRsHEU41liRJkqSNWWbr2PDhcOyx2VRjSZIkSdJ6ltk6V63CfffB/PlFJ5EkSZKk+mGZrXOVSrZ2qrEkSZIkrWeZrXP77w9veYtlVpIkSZLassyWQKUCt90GixYVnUSSJEmS6oNltgQqlexas1OmFJ1EkiRJkuqDZbYE3vIW2G8/pxpLkiRJUivLbAlEZKOzN90ES5cWnUaSJEmSimeZLYlqFVavhmuuKTqJJEmSJBXPMlsSxx4Lu+3mVGNJkiRJAstsafTpA+PGZSOzK1YUnUaSJEmSimWZLZFqFV5/PTt2VpIkSZKamWW2RE46CbbfHiZMKDqJJEmSJBXLMlsi/fvD2LEwdSqsWVN0GkmSJEkqjmW2ZCoVePFFuPXWopNIkiRJUnEssyVz2mkwYIBTjSVJkiQ1N8tsyQweDGPGZJfoWbeu6DSSJEmSVAzLbAlVKvDcczBrVtFJJEmSJKkYltkSOvNMaGnJRmclSZIkqRlZZktop52yy/RMmAApFZ1GkiRJknqfZbakKhV4/HGYM6foJJIkSZLU+yyzJTV+fLZ2qrEkSZKkZmSZLandd4djj/USPZIkSZKak2W2xKpVuPdeePrpopNIkiRJUu+yzJZYpZKtJ00qNIYkSZIk9TrLbIkdcAAcdphTjSVJkiQ1H8tsyVWrcNttsHhx0UkkSZIkqfdYZkuuUoF162DKlKKTSJIkSVLvscyW3OGHw777eokeSZIkSc3FMltyEdno7E03wauvFp1GkiRJknqHZbYBVCqwahVcc03RSSRJkiSpd1hmG8Db3w677upUY0mSJEnNwzLbAPr2hXHjspHZlSuLTiNJkiRJtWeZbRDVKixblh07K0mSJEmNzjLbIEaNgu23d6qxJEmSpOZgmW0Q/fvDGWfA5MmwZk3RaSRJkiSptiyzDaRahRdfhNtuKzqJJEmSJNWWZbaBjBkDAwbAhAlFJ5EkSZKk2rLMNpDBg+G002DSJEip6DSSJEmSVDuW2QZTqcCzz8Ls2UUnkSRJkqTascw2mLFjs+vOOtVYkiRJUiOzzDaYnXaCk07yEj2SJEmSGptltgFVKvDoozBnTtFJJEmSJKk2LLMNaPz4bO3orCRJkqRGZZltQHvsAcccY5mVJEmS1Lgssw2qUoFZs+CZZ4pOIkmSJEk9zzLboCqVbD1pUqExJEmSJKkmLLMN6k1vgkMP9RI9kiRJkhqTZbaBVatw662wZEnRSSRJkiSpZ1lmG1ilAuvWwdSpRSeRJEmSpJ5lmW1gRxwBe+/tVGNJkiRJjccy28AisqnGN94Ir71WdBpJkiRJ6jmW2QZXqcCqVXDNNUUnkSRJkqSeY5ltcO94B+yyC0ycWHQSSZIkSeo5ltkG17cvjBsH06bBypVFp5EkSZKknmGZbQKVCixbBjffXHQSSZIkSeoZltkmcPLJsN12TjWWJEmS1Dgss01gm23gjDNg8mRYs6boNJIkSZK09SyzTaJahRdegNtvLzqJJEmSJG09y2yTGDMmG6F1qrEkSZKkRmCZbRLbbgvveldWZlMqOo0kSZIkbR3LbBOpVuGZZ+Dee4tOIkmSJElbxzLbRMaOza47O2FC0UkkSZIkaetYZpvIzjvDiSd63KwkSZKk8rPMNplKBebMgUcfLTqJJEmSJG05y2yTGT8+Wzs6K0mSJKnMLLNNZsQIOPpoy6wkSZKkcrPMNqFKBe65B559tugkkiRJkrRlLLNNqFrN1pMmFRpDkiRJkraYZbYJvelNcMghTjWWJEmSVF6W2SZVqcDMmfDCC0UnkSRJkqTus8w2qWoV1q2DqVOLTiJJkiRJ3WeZbVJHHgl77w0TJhSdRJIkSZK6zzLbpCKyqcY33givvVZ0GkmSJEnqHstsE6tU4I034Lrrik4iSZIkSd1jmW1ixx0Hw4Y51ViSJElS+Vhmm1jfvjBuHEyblo3QSpIkSVJZWGabXKWSHTN7881FJ5EkSZKkrqtZmY2IARFxd0Q8EBEPR8Q38u07RcSNEfFEvt6xzXMuiIi5EfFYRJxWq2xa75RTYMgQmDix6CSSJEmS1HW1HJl9Azg5pXQ4cAQwJiKOBb4E3JxSOhC4Ob9PRBwCnAMcCowBfhgRfWuYT8A228AZZ8DkybB2bdFpJEmSJKlralZmU2ZZfrdfviRgHHBZvv0yYHx+exxweUrpjZTSU8Bc4Oha5dN6lQosWQK33150EkmSJEnqmpoeMxsRfSPifmAxcGNK6S5g15TSQoB8vUu++x7As22eviDfphp797uzEVqnGkuSJEkqi5qW2ZTS2pTSEcAI4OiIOKyD3aO9l9hkp4jzImJWRMxasmRJDyVtbkOGwOjR2SV60iY/cUmSJEmqP71yNuOU0ivADLJjYRdFxHCAfL04320BsGebp40Anm/ntX6SUhqZUho5bNiwWsZuKtUqPPMM3Hdf0UkkSZIkqXO1PJvxsIjYIb89EDgVeBSYApyb73YuMDm/PQU4JyK2iYh9gQOBu2uVTxsaOxb69HGqsSRJkqRyqOXI7HBgekQ8CNxDdszs1cC3gdER8QQwOr9PSulh4ErgEeA64JMpJc+v20uGDoUTTsimGkuSJElSvWup1QunlB4Ejmxn+4vAKZt5zr8A/1KrTOpYtQqf/jQ89hgcdFDRaSRJkiRp83rlmFmVw/jx2dqpxpIkSZLqnWVWf7bnnnDUUZZZSZIkSfXPMqsNVCpw992wYEHRSSRJkiRp8yyz2kC1mq0nTSo0hiRJkiR1yDKrDRx0EBx8sFONJUmSJNU3y6w2UanAzJnw4otFJ5EkSZKk9llmtYlqFdauhalTi04iSZIkSe2zzGoTb30r7LWXU40lSZIk1S/LrDYRkU01vv56WLas6DSSJEmStCnLrNpVqcAbb8B11xWdRJIkSZI2ZZlVu975Thg6FCZMKDqJJEmSJG3KMqt29e0L48bBtGmwalXRaSRJkiRpQ5ZZbValAq++Cn/4Q9FJJEmSJGlDlllt1imnwJAhTjWWJEmSVH8ss9qsAQPg9NNh8uTsurOSJEmSVC8ss+pQpQKLF8MddxSdRJIkSZLWs8yqQ6efDv37w8SJRSeRJEmSpPUss+rQkCEwenRWZlMqOo0kSZIkZSyz6lS1CvPnw/33F51EkiRJkjKWWXVq7Fjo08epxpIkSZLqh2VWnRo2DI4/3kv0SJIkSaoflll1SbUKDz8MTzxRdBJJkiRJssyqi8aPz9ZONZYkSZJUDyyz6pK99oKRI51qLEmSJKk+WGbVZZUK3HUXPPdc0UkkSZIkNTvLrLqsUsnWkyYVGkOSJEmSLLPquoMPhje/2eNmJUmSJBXPMqtuqVRgxgx46aWik0iSJElqZpZZdUu1CmvXwtSpRSeRJEmS1Mwss+qWt70N9tzTqcaSJEmSimWZVbdEZNecvf56eP31otNIkiRJalaWWXVbtQorV8J11xWdRJIkSVKzssyq2975Tth5Z6caS5IkSSqOZVbd1tIC48bB1VfDqlVFp5EkSZLUjCyz2iKVCixdCtOnF51EkiRJUjPqcpmNiL4RsXtE7NW61DKY6tupp8K228KECUUnkSRJktSMulRmI+JTwCLgRmBavlxdw1yqcwMGwOmnw+TJ2XVnJUmSJKk3dXVk9jPAQSmlQ1NKf5Evb6llMNW/SgUWLYI77yw6iSRJkqRm09Uy+yywtJZBVD6nnw79+zvVWJIkSVLva+nifvOAGRExDXijdWNK6eKapFIpbLddduzsxInwne9ARNGJJEmSJDWLro7MPkN2vGx/YEibRU2uUoGnnoIHHig6iSRJkqRm0qWR2ZTSNwAiYkh2Ny2raSqVxllnwcc+lo3OHnFE0WkkSZIkNYuuns34sIi4D3gIeDgiZkfEobWNpjLYZRd45zuzMitJkiRJvaWr04x/Anw+pbR3Smlv4O+An9YulsqkWoU//hHmzi06iSRJkqRm0dUyOzilNL31TkppBjC4JolUOuPHZ2tHZyVJkiT1lq6W2XkR8dWI2CdfvgI8VctgKo+994a3vtVL9EiSJEnqPV0tsx8BhgETgIn57Q/XKpTKp1qFO++E558vOokkSZKkZtClMptSejml9OmU0ltTSkemlD6TUnq51uFUHpVKtp48udgckiRJkppDh2U2Ir6br6dGxJSNl15JqFI4+GA46CCnGkuSJEnqHZ1dZ/ZX+fo7tQ6icovIRme/8x146SXYaaeiE0mSJElqZB2OzKaUZuc3j0gpzWy7AEfUPJ1KpVKBNWvg6quLTiJJkiSp0XX1BFDntrPtQz2YQw1g5EgYMcJL9EiSJEmqvQ6nGUfE+4D3A/ttdIzsEODFWgZT+fTpk11z9tJL4fXXYbBXIpYkSZJUI50dM3sHsBAYCvxHm+2vAQ/WKpTKq1qFSy6B66/PbkuSJElSLXRYZlNKT0fEAuD1/DhZqUPHHw8775xNNbbMSpIkSaqVTo+ZTSmtBZZHxPa9kEcl19ICY8fC1KmwalXRaSRJkiQ1qq6eAGol8MeIuDQivte61DKYyqtahaVLYcaMopNIkiRJalSdHTPbalq+SJ0aPTo7+dPEifCudxWdRpIkSVIj6lKZTSldFhH9gTflmx5LKa2uXSyV2YABcPrpMGkS/OAH2VmOJUmSJKkndalmRMRJwBPAD4AfAo9HxAm1i6Wyq1TgT3+CO+8sOokkSZKkRtTVMbP/AN6VUjoxpXQCcBrwn7WLpbI7/XTo1w8mTCg6iSRJkqRG1NUy2y+l9FjrnZTS40C/2kRSI9h+ezj11Oy42ZSKTiNJkiSp0XS1zM7Kz2R8Ur78FJhdy2Aqv0oF5s2DP/6x6CSSJEmSGk1Xy+wngIeBTwOfAR4BPlarUGoM48ZBhFONJUmSJPW8rpbZj6eULk4pVVNKlZTSf5IVXGmzdtkF3vnObKqxJEmSJPWkrpbZc9vZ9qEezKEGVanAgw/Ck08WnUSSJElSI+mwzEbE+yJiKrBvRExps8wAXuyVhCq1SiVbOzorSZIkqSe1dPL4HcBCYCjZ5XlavQY8WKtQahz77ANHHpmV2b//+6LTSJIkSWoUHY7MppSeTinNAE4Fbk0pzSQrtyOAqH08NYJqFe64AxYuLDqJJEmSpEbR1WNmbwEGRMQewM3Ah4Ff1CqUGkvrVOPJk4vNIUmSJKlxdLXMRkppOVAFvp9SqgCH1C6WGskhh8CBB3qJHkmSJEk9p8tlNiLeDnwAmJZv6+x4WwnIrjVbrcL06fDyy0WnkSRJktQIulpmPwtcAExMKT0cEfsB02uWSg2nUoE1a2DatM73lSRJkqTOdKnMppRmppTOSin9W35/Xkrp07WNpkZy1FGwxx5ONZYkSZLUMzqcKhwR300pfTa/1mza+PGU0lk1S6aG0qcPjB8PP/85LF8OgwYVnUiSJElSmXV23Ouv8vV3ah1Eja9SgR/8AK6/fv0ZjiVJkiRpS3RYZlNKs/P1zIgYlt9e0hvB1HhOOAF22gkmTrTMSpIkSdo6HR4zG5l/iogXgEeBxyNiSUR8rXfiqZH06wdjx8LUqbB6ddFpJEmSJJVZZyeA+ixwHHBUSmnnlNKOwDHAcRHxuVqHU+OpVuGVV2DGjKKTSJIkSSqzzsrsXwPvSyk91bohpTQP+GD+mNQto0fD4MHZVGNJkiRJ2lKdldl+KaUXNt6YHzfbrzaR1MgGDoQxY2DSJFi3rug0kiRJksqqszK7agsfkzarWoWFC+Guu4pOIkmSJKmsOrs0z+ER8Wo72wMYUIM8agJnnJGdDGrCBHj724tOI0mSJKmMOhyZTSn1TSlt184yJKXkNGNtke23h1NOyY6bTanoNJIkSZLKqLNpxlssIvaMiOkRMSciHo6Iz+Tbd4qIGyPiiXy9Y5vnXBARcyPisYg4rVbZVLxKBZ58Eh56qOgkkiRJksqoZmUWWAP8XUrpYOBY4JMRcQjwJeDmlNKBwM35ffLHzgEOBcYAP4yIvjXMpwKNGwcR2VRjSZIkSequmpXZlNLClNK9+e3XgDnAHsA44LJ8t8uA8fntccDlKaU38ksBzQWOrlU+FWvXXeG447xEjyRJkqQtU8uR2T+LiH2AI4G7gF1TSgshK7zALvluewDPtnnagnzbxq91XkTMiohZS5YsqWlu1ValAg88APPmFZ1EkiRJUtnUvMxGxLbAVcBnU0rtnRn5z7u2s22T0wOllH6SUhqZUho5bNiwnoqpAlQq2drRWUmSJEndVdMyGxH9yIrsb1JKrUdHLoqI4fnjw4HF+fYFwJ5tnj4CeL6W+VSsffeFI46wzEqSJEnqvlqezTiAS4E5KaWL2zw0BTg3v30uMLnN9nMiYpuI2Bc4ELi7VvlUHyoVuOMO+NOfik4iSZIkqUxqOTJ7HPBXwMkRcX++nA58GxgdEU8Ao/P7pJQeBq4EHgGuAz6ZUlpbw3yqA9Vqdq3ZyZM731eSJEmSWkVKmxyWWhojR45Ms2bNKjqGtkJK8KY3wX77wfXXF51GkiRJUj2JiNkppZHtPdYrZzOWNiciG539wx/glVeKTiNJkiSpLCyzKlylAmvWwLRpRSeRJEmSVBaWWRXu6KNh+HCYMKHzfSVJkiQJLLOqA336ZKOz110Hy5cXnUaSJElSGVhmVRcqlazI3nBD0UkkSZIklYFlVnXhxBNhxx1h4sSik0iSJEkqA8us6kK/fjB2LEydCqtXF51GkiRJUr2zzKpuVCrw8sswc2bRSSRJkiTVO8us6sa73gWDBjnVWJIkSVLnLLOqG4MGwZgxWZldt67oNJIkSZLqmWVWdaVahYUL4e67i04iSZIkqZ5ZZlVXzjgDWlqcaixJkiSpY5ZZ1ZUddoCTT4YJEyClotNIkiRJqleWWdWdahXmzoWHHy46iSRJkqR6ZZlV3Rk3DiKy0VlJkiRJao9lVnVnt93gHe/wuFlJkiRJm2eZVV2qVOD+++Gpp4pOIkmSJKkeWWZVlyqVbO3orCRJkqT2WGZVl/bbDw4/3DIrSZIkqX2WWdWtSgVuvx0WLSo6iSRJkqR6Y5lV3apWs2vNTp5cdBJJkiRJ9cYyq7p12GGw//5ONZYkSZK0Kcus6lZENtX45pth6dKi00iSJEmqJ5ZZ1bVqFVavhmnTik4iSZIkqZ5YZlXXjjkGhg+HCROKTiJJkiSpnlhmVdf69IHx4+Haa2HFiqLTSJIkSaoXllnVvUoFli+HG28sOokkSZKkemGZVd076STYYQenGkuSJElazzKrutevH4wdC1OnZieDkiRJkiTLrEqhUoGXXoJbbik6iSRJkqR6YJlVKZx2GgwcCBMnFp1EkiRJUj2wzKoUBg2CMWNg0iRYt67oNJIkSZKKZplVaVQq8NxzcM89RSeRJEmSVDTLrErjzDOhpcWpxpIkSZIssyqRHXeEUaOyS/SkVHQaSZIkSUWyzKpUqlV44gl45JGik0iSJEkqkmVWpTJuHEQ41ViSJElqdpZZlcrw4XDssdlUY0mSJEnNyzKr0qlW4b77YP78opNIkiRJKoplVqVTqWRrpxpLkiRJzcsyq9LZf394y1sss5IkSVIzs8yqlCoVuO02WLSo6CSSJEmSimCZVSlVq9m1ZqdMKTqJJEmSpCJYZlVKf/EXsN9+TjWWJEmSmpVlVqUUkU01vukmWLq06DSSJEmSeptlVqVVrcLq1XDNNUUnkSRJktTbLLMqrWOPhd12c6qxJEmS1IwssyqtPn1g/PhsZHbFiqLTSJIkSepNllmVWqUCr7+eHTsrSZIkqXlYZlVqJ50E228PEyYUnUSSJElSb7LMqtT694exY2HqVFizpug0kiRJknqLZValV6nAiy/CrbcWnUSSJElSb7HMqvROOw0GDnSqsSRJktRMLLMqvcGDs0I7cSKsW1d0GkmSJEm9wTKrhlCpwHPPwaxZRSeRJEmS1Bsss2oIZ54JLS3Z6KwkSZKkxmeZVUPYaafsMj0TJkBKRaeRJEmSVGuWWTWMahUefxzmzCk6iSRJkqRas8yqYYwbl62daixJkiQ1PsusGsbuu8Oxx3qJHkmSJKkZWGbVUKpVuPdeePrpopNIkiRJqiXLrBpKpZKtJ00qNIYkSZKkGrPMqqEccAD8xV841ViSJElqdJZZNZxKBW67DRYvLjqJJEmSpFqxzKrhVCqwbh1MmVJ0EkmSJEm1YplVwzn8cNh3Xy/RI0mSJDUyy6waTkQ2OnvTTfDqq0WnkSRJklQLllk1pGoVVq2Ca64pOokkSZKkWrDMqiG9/e2w665ONZYkSZIalWVWDalPHxg3LhuZXbmy6DSSJEmSepplVg2rWoVly7JjZyVJkiQ1FsusGtaoUbD99k41liRJkhqRZVYNq39/OPNMmDwZ1qwpOo0kSZKknmSZVUOrVODFF+G224pOIkmSJKknWWbV0MaMgQEDYMKEopNIkiRJ6kmWWTW0wYPhtNNg0iRIqeg0kiRJknqKZVYNr1KBZ5+F2bOLTiJJkiSpp1hm1fDGjoW+fZ1qLEmSJDUSy6wa3k47wUkneYkeSZIkqZFYZtUUKhV49FGYM6foJJIkSZJ6gmVWTWH8+Gzt6KwkSZLUGCyzagp77AHHHGOZlSRJkhqFZVZNo1qFWbPgmWeKTiJJkiRpa9WszEbEzyNicUQ81GbbThFxY0Q8ka93bPPYBRExNyIei4jTapVLzemii2D48Oz2pEnZevr0bLskSZKk8qnlyOwvgDEbbfsScHNK6UDg5vw+EXEIcA5waP6cH0ZE3xpmU5M56ij4/Odhn32yS/RMnw5nn51tlyRJklQ+NSuzKaVbgJc22jwOuCy/fRkwvs32y1NKb6SUngLmAkfXKpuaz6hRcOWVsHgxzJwJp58O//Ef2XZJkiRJ5dPbx8zumlJaCJCvd8m37wE822a/Bfk2qceMGgV/+7fZ7VWr4Nxzs1J7/fWwbl2x2SRJkiR1T72cACra2Zba3THivIiYFRGzlixZUuNYaiTTp8MvfgFf/SrssAN86ENw330wZgwccgj84AewbFnBISVJkiR1SW+X2UURMRwgXy/Oty8A9myz3wjg+fZeIKX0k5TSyJTSyGHDhtU0rBpH6zGyV14JF14Iv/89XH01XHYZ/PrXsN12cP752SV8Pv95mDev6MSSJEmSOtLbZXYKcG5++1xgcpvt50TENhGxL3AgcHcvZ1MDu+eerMi2HiPbegzt/ffDBz4Ad98N//u/cMYZ8P3vwwEHwLhxcPPNkNqdIyBJkiSpSJFq9Jt6RPwWOAkYCiwCvg5MAq4E9gKeAf4ypfRSvv8/Ah8B1gCfTSld29l7jBw5Ms2aNasW8dXEnn8efvQj+H//D5YsgUMPhU9/Gj74QRg0qOh0kiRJUvOIiNkppZHtPlarMtsbLLOqpZUr4Yor4L/+Kzu2dscd4aMfhU9+Evbeu+h0kiRJUuPrqMzWywmgpLozYEB2xuPZs+HWW+HUU+Hii2G//eA978ku8VPivwVJkiRJpWaZlToRAe98Z3aM7bx58MUvwowZcNJJcOSR8POfw4oVRaeUJEmSmotlVuqGvfaCf/1XWLAAfvrT7Pq0//f/wp57wj/+Y7ZdkiRJUu1ZZqUtMHBgdvzsAw9kl/05/nj49rdhn33gve+FO+5wCrIkSZJUS5ZZaStEZNONJ06EuXPhc5+DG26A446Do46CX/4S3nij6JSSJElS47HMSj1k333h3/89m2r8ox/B8uXZCaT22gu+/nVYuLDohJIkSVLjsMxKPWzwYPj4x+Hhh7NR2qOPhm9+M7uczwc/CHffXXRCSZIkqfwss1KNRMDo0TB1Kjz+OPzt38KUKXDMMXDssfDb38KqVUWnlCRJksrJMiv1ggMOgO9+F557Dr7/fXjpJXj/+7MTRn3zm7B4cdEJJUmSpHKxzEq9aMgQOP98ePRRuOYaOPxw+NrXskv7fOhDcO+9RSeUJEmSysEyKxWgTx9497vh2mthzhz4m7+B3/8e3va27DI/v/sdrFlTdEpJkiSpfllmpYK9+c1wySXZFOSLL4bnn4ezz87Ojvztb8MLLxSdUJIkSao/llmpTmy/fXad2scfz04UddBBcMEF2RTkj34UHnyw6ISSJElS/bDMSnWmb18YOxZuugkeeii7Vu3//E92fO2oUTBxIqxdW3RKSZIkqViWWamOHXoo/PjHsGABXHQRzJsH1Srsvz985zvw8stFJ5QkSZKKYZmVSmCnneALX4Ann4Srrsou6fOFL8CIEfDxj8MjjxSdUJIkSepdllmpRFpaspHZGTPg/vvhnHPgF7/IRnBHj4apU2HduoJDSpIkSb3AMiuV1OGHw6WXZlOQv/Wt7BI/Z50Fb3oTfPe7sHRp0QklSZKk2rHMSiU3dGh21uOnnoIrroDddsvOirzHHnD++fDYY0UnlCRJknqeZVZqEP36Zdenve02mDUL3vMe+OlPs+vYvvvdcO21TkGWJElS47DMSg3obW+Dyy6DZ56Bb3wjO7729NPh4IPhkkvgtdeKTihJkiRtHcus1MB23RW+9jV4+mn4zW9ghx3gU5/KzoL8uc9lZ0eWJEmSysgyKzWB/v3h/e+Hu+6CO++EM8/MRmgPPBDGjoWbboKUik4pSZIkdZ1lVmoyxxyTjdI+/TR85StZwR09Gg47DH78Y3j99aITSpIkSZ2zzEpNavfd4cILs+NqL7sMBgyAT3wim4L8hS/A/PlFJ5QkSZI2zzIrNbkBA+Cv/zo7A/Jtt8G73gX/+Z+w//5QrcKMGU5BliRJUv2xzEoCIAKOOy67Vu38+fAP/wC33AKjRsERR8Cll8KKFUWnlCRJkjKWWUmbGDECvvUtePbZrMQCfPSj2fYLLsi2S5IkSUWyzErarIED4SMfya5TO2MGnHQSXHQR7LsvnH12Ni3ZKciSJEkqgmVWUqci4MQT4aqrsmvTfv7zcOONcPzxMHJkdgKplSuLTilJkqRmYpmV1C377JONzi5YkF3KZ+VK+NCHYK+94Gtfg+efLzqhJEmSmoFlVtIWGTwYPvYxeOghuOkmOPZY+Od/hr33hve/P7t+rSRJklQrlllJWyUCTjkFpkyBJ56AT30Kpk3Lyu0xx8BvfgOrVhWdUpIkSY3GMiupx+y/P1x8cTYF+ZJL4JVX4IMfzEZrL7wQFi0qOqEkSZIahWVWUo8bMgQ++UmYMweuvRaOPBK+/vXsuNpzz4XZs7P9LroIpk/f8LnTp2fbJUmSpI5YZiXVTJ8+MGYMXHMNPPYYnHceTJiQnQH5uONg2bLsEj+thXb69Oz+UUcVm1uSJEn1L1KJLxI5cuTINGvWrKJjSOqGpUvhF7+A738/u8zP0KGwfDl84ANZ0f3d72DUqKJTSpIkqR5ExOyU0sh2H7PMSirC2rXZFOTvfS+7Zm2rXXaBAw7Ilv3333C9007ZCackSZLUHDoqsy29HUaSAPr2hTPPzC7xM2sWnHwyXHcdvO1tsGIF/OEP8Mtfbvic7bdvv+Tuvz8MH55Na5YkSVJzsMxKKkzrMbJXXZVNLW69f+WV2f0VK+Cpp7LpyHPnrl/Pnp09Z+3a9a81cCDst9+GJbf19l57QYv/bydJktRQ/PVOUmHuuWd9cYVsfeWV2fZRo7KCesgh2bKx1avhmWc2Lbpz58L118PKlev3bWmBffZpf1R3331hwIBe+biSJEnqQR4zK6nhrFsHCxduWHLblt1XX12/bwSMGLFpyW29PWRIcZ9DkiSp2XnMrKSm0qcP7LFHtpx44oaPpQQvvth+0Z0yBRYv3nD/XXZp/xjdAw6AnXf2hFSSJElFscxKaioR2eWAhg6FY4/d9PHXXtu05D75JMyYAb/+dVaGW2233eZPSLX77p6QSpIkqZYss5LUxpAhcMQR2bKxlSvbPyHV/ffDxImwZs36fQcMyEpte0V37709IZUkSdLW8tcpSeqiAQPg4IOzZWNr1sCzz256fO6TT2bX0V2xYv2+LS1Zod3cCakGDuy9zyRJklRWlllJ6gEtLVkR3XdfGD16w8dS2vwJqe68E5Yu3XD/jk5Itd12vfeZJEmS6pllVpJqLCI7hnb33eGEEzZ8LCV46aX2j9O9+mpYtGjD/YcN2/wJqYYO9YRUkiSpeVhmJalAEdlZkXfeGY4+etPHX3sN5s3btOzecgv85jcbnpBqyJD2S+4BB3hCKkmS1Hgss5JUx4YMgcMPz5aNvfFG+yekevBBmDwZVq9ev+8223R8Qqp+/bL9LroIjjoKRo1a/9zp0+Gee+CLX6ztZ5UkSeoOy6wkldQ228Cb35wtG1u7dtMTUrWub74Zli9fv2/fvutPSDVgAFx4IXzpSzB2LMyZA+efD1dc0XufS5IkqSsitZ2jVjIjR45Ms2bNKjqGJJVKSvCnP7VfdOfOhVde2fQ5EbD99tmyww7rl7b3O3vMyxFJkqTuiojZKaWR7T3mrxaS1GQiYPjwbDn++E0ff+mlbErxpZdmo7MnnZQV3KVLs3Xr7fnz199/9dUNj99tz+DBW1aCW28PGNATn16SJDUKy6wkaQMPPJAdc/vVr8KPfgSf+9yGx9C2Z9267GRVG5fe9kpw6+1Fi+Dxx9ffX7Om4/fYZputGxnedlvP9ixJUiOxzEqS/mz6dDj7bLjyyqzAjhq14f3N6dNn/TTkLZFSdhzv5orv5krxM8+sv79iRcfv0bfv+oK7JSPD222XvYYkSaoPlllJ0p/dc8+GxXXUqOz+Pfd0Pjq7NSKyaciDB2eXEdoSb7yRldqujgy/8sr6Y4RfeSUbWe7MkCHdL8Ft7/fvv2WfzbNMS5K0KU8AJUkS2RmgX321ayV4c4+tW9fxewwcuGUl+OGH4ROfyP6wcPLJm46gS5LUqDo6AZRlVpKkHpASLFu2ZSW4dVm1qvP32Wab7BrCu+8OQ4euH9Fuuwwa1LVtbbcPGpRNF5ckqZ54NmNJkmosIpuGPGQIjBixZa+xcmXHJXjKFLj9djjiiOz6wq+/ni1Ll8Lzz2fHHbdue/31zs8wvbGBA7e8DHe2bZttPAGXJKlnWWYlSaoTAwbAbrtly8amT4d///f1Z5m++OKOpxinlJXj11/ftORubtvmti9atOn2lSu799n69Ol68d2S4tyvX/fybC2PY5ak4llmJUmqc1tylumIbKR14MDaZFq7NjuDdFcLcUel+qWXNt3e2aWaNtav35aV5K4U5/amYB911IbfQdvvSJLUOyyzkiTVuaLOMt2Rvn2za/duu21tXn/16q0rya3bW6dgb7zvlkzB3rj47r47nHYaHHAAzJsHo0dn12i+4Yb1f0jo7jJggNOxJamrPAGUJElqKm2nYHc2atxZeX7iCVi4MDvz9IAB2Wj1ihVZGd9SAwZseRnubBk0aNNtXj9ZUj3zBFCSJEm5tlOwhw7d8tdpnVrcehzzb3+7fqR8zZqsMLeW2+4sy5dv/rGXXmp/e3ePYW6rX7/alef2lv79azf67LHMUnOxzEqSJHVTZ8cxt7TUdhr2xlpHm7ekPHe0vP46vPBC+4+tXbtlWdv+MaGnR5t32gne8x748Y+z7+Guu+DDH4bLL+/Zn7ek+mCZlSRJ6qZ6O4651if8as/q1T0z2rzxsnhx+9u7ch3mVu9974b3Tz01G4Hu3z+7TFTr0p37tXhu//6Nf31nR8tVS5ZZSZKkbmrvl/DWEdpm0a9ftmy3Xe+839q1XR99vvxymDYtK7EnnwxvvLF+WbWq/dut95ct6/jx7pTqruisZBdRuHuyZHvmb9WSZVaSJEl1r2/f9WeS7sj06dn04tZjmb/85Z79I0NK60vt5kpyV0pzd5/bWrI3t29Pl+yWlp4r0WedBWPHwjvfCbffDuedB/Pnw69+lZX5lpZs6anbjT7a3RMaZcTcMitJkqSGsCXXZO6uiPUlbciQnnnNnpBSNvV7a0tzd+8vW9b567a6/vpsffHFtf1Z9OnT8wW5Xm9vaXFvlBFzy6wkSZIaQr0dy9ybIrIR0f79669k33gjvP/98KEPwX//dzZifvTR2Vm/16zJSni93F65csueu25dMT/fiPXFtruFeM89s2tl/9VfwZQpPftHn97idWYlSZIk1cTGo+Ub328U69Zlx3UXXca7e3v+fHjuuWxa/oUXFv1TbJ/XmZUkSZLU65pltLxPn2zp16/oJF238bWyy3gSO0dmJUmSJKmJlGnEvKORWc/1JUmSJElNpKMR8zJxZFaSJEmSVJccmZUkSZIkNRTLrCRJkiSpdCyzkiRJkqTSscxKkiRJkkrHMitJkiRJKh3LrCRJkiSpdCyzkiRJkqTSscxKkiRJkkrHMitJkiRJKp26K7MRMSYiHouIuRHxpaLzSJIkSZLqT12V2YjoC/wAeDdwCPC+iDik2FSSJEmSpHpTV2UWOBqYm1Kal1JaBVwOjCs4kyRJkiSpztRbmd0DeLbN/QX5tj+LiPMiYlZEzFqyZEmvhpMkSZIk1Yd6K7PRzra0wZ2UfpJSGplSGjls2LBeiiVJkiRJqif1VmYXAHu2uT8CeL6gLJIkSZKkOhUppc736iUR0QI8DpwCPAfcA7w/pfTwZvZfAjzdewm3yFDghaJDaAN+J/XJ76X++J3UJ7+X+uN3Up/8XuqP30l9qvfvZe+UUrtTclt6O0lHUkprIuJ84HqgL/DzzRXZfP+6n2ccEbNSSiOLzqH1/E7qk99L/fE7qU9+L/XH76Q++b3UH7+T+lTm76WuyixASuka4Jqic0iSJEmS6le9HTMrSZIkSVKnLLO195OiA2gTfif1ye+l/vid1Ce/l/rjd1Kf/F7qj99JfSrt91JXJ4CSJEmSJKkrHJmVJEmSJJWOZbZGIuLnEbE4Ih4qOosyEbFnREyPiDkR8XBEfKboTM0uIgZExN0R8UD+nXyj6ExaLyL6RsR9EXF10VkEETE/Iv4YEfdHxKyi8ygTETtExO8j4tH8vy9vLzpTM4uIg/L/jbQur0bEZ4vOJYiIz+X/rX8oIn4bEQOKztTsIuIz+ffxcFn/d+I04xqJiBOAZcAvU0qHFZ1HEBHDgeEppXsjYggwGxifUnqk4GhNKyICGJxSWhYR/YDbgM+klO4sOJqAiPg8MBLYLqV0ZtF5ml1EzAdGppTq+VqATSciLgNuTSn9LCL6A4NSSq8UHEtkf5ADngOOSSk9XXSeZhYRe5D9N/6QlNKKiLgSuCal9ItikzWviDgMuBw4GlgFXAd8IqX0RKHBusmR2RpJKd0CvFR0Dq2XUlqYUro3v/0aMAfYo9hUzS1lluV3++WLf2GrAxExAjgD+FnRWaR6FRHbAScAlwKklFZZZOvKKcCTFtm60QIMjIgWYBDwfMF5mt3BwJ0ppeUppTXATKBScKZus8yqKUXEPsCRwF0FR2l6+VTW+4HFwI0pJb+T+vBd4IvAuoJzaL0E3BARsyPivKLDCID9gCXAf+dT8n8WEYOLDqU/Owf4bdEhBCml54DvAM8AC4GlKaUbik3V9B4CToiInSNiEHA6sGfBmbrNMqumExHbAlcBn00pvVp0nmaXUlqbUjoCGAEcnU97UYEi4kxgcUppdtFZtIHjUkpvBd4NfDI/nEXFagHeCvwopXQk8DrwpWIjCSCf8n0W8LuiswgiYkdgHLAvsDswOCI+WGyq5pZSmgP8G3Aj2RTjB4A1hYbaApZZNZX8uMyrgN+klCYUnUfr5VPzZgBjik0i4DjgrPwYzcuBkyPi18VGUkrp+Xy9GJhIdpyTirUAWNBmRsnvycqtivdu4N6U0qKigwiAU4GnUkpLUkqrgQnAOwrO1PRSSpemlN6aUjqB7PDIUh0vC5ZZNZH8ZEOXAnNSShcXnUcQEcMiYof89kCy/9g9WmgokVK6IKU0IqW0D9k0vT+klPwLeoEiYnB+4jryaazvIpsipgKllP4EPBsRB+WbTgE8qWB9eB9OMa4nzwDHRsSg/PexU8jOXaICRcQu+XovoEoJ/zfTUnSARhURvwVOAoZGxALg6ymlS4tN1fSOA/4K+GN+jCbAl1NK1xQXqekNBy7LzzjZB7gypeRlYKRN7QpMzH4HpAX4n5TSdcVGUu5TwG/yaa3zgA8XnKfp5cf/jQY+VnQWZVJKd0XE74F7yaay3gf8pNhUAq6KiJ2B1cAnU0ovFx2ou7w0jyRJkiSpdJxmLEmSJEkqHcusJEmSJKl0LLOSJEmSpNKxzEqSJEmSSscyK0mSJEkqHcusJEklEBH7RITXlpUkKWeZlSRJkiSVjmVWkqSSiYj9IuK+iDiq6CySJBXFMitJUolExEHAVcCHU0r3FJ1HkqSitBQdQJIkddkwYDLwnpTSw0WHkSSpSI7MSpJUHkuBZ4Hjig4iSVLRHJmVJKk8VgHjgesjYllK6X8KziNJUmEss5IklUhK6fWIOBO4MSJeTylNLjqTJElFiJRS0RkkSZIkSeoWj5mVJEmSJJWOZVaSJEmSVDqWWUmSJElS6VhmJUmSJEmlY5mVJEmSJJWOZVaSJEmSVDqWWUmSJElS6VhmJUmSJEml8/8B5XTKCATT1pgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5320783503581544"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(X_train,prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5941146183752026"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(X_test, prediction_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
